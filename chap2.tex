\chapter{Composants de base d'un assistant personnel}

\section{Introduction}
	\paragraph{}
	Durant ce chapitre, nous allons détailler un peu plus l'aspect technique d'une architecture typique pour un SPA, nous commencerons d'abord par définir des notions de bases ainsi que des techniques d'apprentissage automatique, nous traiterons celles qui ont été les plus utilisées pour les travaux que nous avons trouvé. La suite du chapitre sera organisé en sections qui décrirons chacune le fonctionnement d'une partie du SPA, en citant les travaux et références qui relatent de cette dernière. Nous terminerons sur une conclusion qui introduira le chapitre suivant.
\section{Notions et aspects théoriques}
	\paragraph{}
	Dans cette section nous essaierons de présenter différentes notions liées au domaine de l'apprentissage automatique, pour ensuite les citer dans les module qui leur font appel. 
	\subsection{Apprentissage automatique}
		\paragraph{}
		Le plus souvent, un domaine scientifique peut être défini à travers le, ou les types de problèmes dont il essaye de trouver une solution, d'après \cite{mitchelllearning}, l'auteur à défini ce problème sous forme d'une question :
		\begin{quote}
			\say{How can we build computer systems that automatically improve with experience, and what are the fundamental laws that govern all learning processes?}\cite{mitchelllearning}
		\end{quote}
		que nous pouvons traduire par :
		\begin{quote}
			\say{Comment pourrions nous développer un système informatique qui pourrait s'améliorer à travers l'expérience, et quelles seraient les lois qui régiraient le processus d'apprentissage?}
		\end{quote}
		\par 
		D'après \cite{mitchelllearning} l'apprentissage automatique est un paradigme qui stipule qu'un système informatique peut apprendre à effectuer un ensemble de tâches T, sachant qu'il dispose d'un ensemble de données E, tout en améliorant sa performance P.
		\par
		Il existe plusieurs sous catégories d'apprentissage automatique, elles différent principalement par la manière dont le système apprend, du type de données sur les quelles il apprend, ainsi que du but de son apprentissage (classification, régression,...). Nous pouvons citer les catégories suivantes :
		\begin{itemize}
			\item  \textbf{Apprentissage supervisé} : Les algorithmes de cette catégories ont besoin d'une assistance externes, les données doivent être séparées en deux parties (ensemble d'apprentissage et de test), un \textit{label} ou classe doit être associée à chaque instance pour permettre à l'algorithme de calculer un certain taux d'erreur qu'il essayera d'améliorer au fur et à mesure qu'une nouvelle instance est présentée \cite{supervised_learning}. Idéalement le système pourra apprendre une certaines fonction $\hat{f} : X \rightarrow Y$ qui liera les entrées $X$ aux sorties $Y$ en minimisant une erreur $E_Y$ 
			
			\item \textbf{Apprentissage non supervisé} : Ici, les algorithmes ne disposent pas d'un étiquetage des données, ils essayeront donc d'apprendre des \textit{pattern} ou motifs fréquents pour grouper les données similaires. De tels algorithmes ne se préoccupent pas de la classe, mais de la similarité entre un groupe de données \cite{unsupervised_learning}
			
			\item \textbf{Apprentissage par renforcement} : Cette dernière catégories d'algorithmes apprennent par un système de \textit{trial and error} \footnote{Essais et erreur ?} en interagissant avec l'environnement pour accomplir une tâche (voir \ref{reinf_learning})
		\end{itemize}
	\subsection{Réseaux de neurones artificiels}
		\paragraph{}
		Un réseau de neurones artificiels est une structure d'appariement non-linéaire inspiré de la façon dont les systèmes nerveux biologiques fonctionnent. Ils permettent de modéliser les relations sous-jacentes des données. ils sont composés d'un nombre arbitrairement large de plus petites unités de calcul interconnectées appelées neurones, qui traient l'information d'une manière parallèle dans le but de résoudre un problème bien spécifique \cite{neural_nets}. Ils ont notamment connu un très grand succès lors des dernières années dans différents domaines comme la reconnaissance d'images \cite{inception}, la reconnaissance automatique de la parole \cite{speech_reco_dnn,speech_reco_Yu2015} ou encore la classification de textes \cite{seq2seq_multitask_classification,dnn_text_classification}.
		\par 
		Il existe une variété d'architectures de réseaux de neurones, nous traiterons dans cette section de trois d'entre elles : 
			\begin{itemize}
				\item Réseaux de neurones multicouches denses
				\item Réseaux de neurones profonds
				\item Réseaux de neurones récurrents et leurs variantes
			\end{itemize}
		\subsubsection{Réseaux de neurones multicouches denses}
		\begin{figure}[H]
			\centering
			\includegraphics[width=0.5\linewidth]{images/notions/mlp.png}
			\caption{Architecture basique d'un réseaux de neurones multicouches}
			\label{mlp}
		\end{figure}
		\paragraph{}
		La forme la plus basique que puisse avoir un réseaux de neurones est celle d'un réseaux multicouches comme montré dans \ref{mlp}, elle se compose de trois parties :
		\begin{itemize}
			\item \textbf{Une couche d'entrée : } cette couche est composé d'un ensemble de neurones ou \textit{perceptron} \cite{perceptron}, elle représente l'information en entrée codifié en un vecteur numérique $\chi$
			
			\item  \textbf{Une ou plusieurs couches cachées :} le coeur du réseau, c'est une succession de couche de neurones dont chaque couche $\omega_i$ reçoit un signal sous forme d'une ou plusieurs valeurs numériques depuis une couche antérieure $\omega_{i-1}$ ou bien la couche d'entrée $\chi$, puis envois en sortie  un autre signal de même nature qui est une combinaison non-linéaire du signal en entrée vers une couche suivante $\omega_{i+1}$ ou bien la couche de sortie
			\item \textbf{Une couche de sortie :}
			elle permet de calculer une valeur $y$ qui peut être vu comme la prédiction du modèle $\Phi$ par rapport à son entrée $\chi$ : 
			\begin{equation}
				y = f_\Phi(\chi)
			\end{equation}
		\end{itemize}
		Le réseau calculera une erreur $e(y,\hat{y}$ en fonction de sa valeur en sortie et de la valeur exacte puis corrigera cette erreur au fur et à mesure du parcoure des données d'apprentissage \cite{mlp}
		
		\subsubsection{Réseaux de neurones profonds}\label{part2DNN}
		\paragraph{}
		Les réseaux de neurones à une seule couche sont dit \textit{shallow}, ils présentaient l'avantage d'être assez rapide durant la phase d'apprentissage, cependant les limites computationnelle d'antan se sont vu vite brisé avec le développement de processeurs plus puissants, de plus avec l'explosion des données sur le web, toutes les conditions nécessaires pour la mise en place d'architectures plus complexes étaient réunies. Les réseaux de neurones profonds sont une adaptation des réseaux multi-couches classiques avec généralement plus de 3 couches cachées. \par même si le principe reste le même, l'apprentissage profond est puissant car les architectures les plus complexes permettent d'extraire automatiquement les caractéristiques qui sont importantes mais non visibles, c'est le cas des réseaux de neurones constitutionnels et récurrents \cite{dnn} 
		
		\subsubsection{Réseaux de neurones récurrents}\label{seq2seqpart2}
		\paragraph{}
		Un aspect que les réseaux de neurones (profonds ou pas) ne peuvent capturé est la notion de séquentialité, en effet beaucoup de problèmes qui sont de nature séquentielle ne peuvent être modélisé par les architectures dites classiques, comme l'analyse d'un texte, l'introduction d'une notion de séquence permet donc de capturer des dépendances entre certains états et leurs voisins, on parle ici de contexte \cite{rnn_lstms}.
		\par 
		Les réseaux de neurones récurrents (RNNs) sont des réseaux de neurones \textit{feedforward} dont certaines connections en sortie sont réintroduite comme entrées dans le réseau durant une étape ultérieur du processus d'apprentissage, ceci introduit la notion de temps dans l'architecture, ainsi à un instant $t$, un neurones récurrent recevra en entré la données $x^{(t)}$ ainsi que la valeur de l'état caché $h^{(t-1)}$ résultante de l'étape précédente du réseau, la valeur en sorite $\hat{y}^{(t)}$ est calculée en fonction de l'état caché $h^{(t)}$, les équations suivantes montrent les calculs effectués :
		\begin{equation}
			h^{(t)} = \tanh(W^{hx} \times x^{(t1)} + W^{hh} \times h^{(t-1)} + b_h)
		\end{equation}
		
		\begin{equation}
			\hat{y}^{(t)} = softmax(W^{hy} \ times h^{(t1)} + b_y)
		\end{equation}
		
		Où $W^{hx}$ est la matrice de poids entre la couche d'entrée et l'état caché et $W^{hh}$ est la matrice de poids de récurrence (entre l'état $t$ et $t-1$) les deux vecteurs $b_h$ et $b_y$ sont les vecteurs de biais et $\times$ est l'opération du produit matriciel\cite{rnn_lstms}
		
		\begin{figure}[H]
			\centering
%			\includegraphics[width=0.5\linewidth]{images/notions/rnns.png}
%			\caption{Un réseau de neurones récurrent durant les différentes étapes $t$ \cite{rnns_online}}
			
			\includegraphics[width=0.5\linewidth]{images/notions/rnns_unrolled_online.png}
			\caption{Architecture interne d'un réseau de neurones récurrent à un instant $t$ \cite{rnns_online}}
		\end{figure}
		\par 
		Un des principaux problèmes que rencontrent les RNNs est celui du \textit{Vanishing gradient} traduit par la \textit{Problème de disparition du gradient} \cite{vanishing_gradient}, les relations à long termes entre dans les séquences ne sont donc pas capturées. Ainsi, pour remédier à ce problème, des architectures de réseaux de neurones dotées d'un module de mémoire ont étés introduites.
		
		\subsubsection{Réseaux de neurones récurrents à mémoire court et long terme (LSTM)}
		\paragraph{}
		Premièrement introduit en 1997 par \textit{	Sepp Hochreiter } et al. dans \cite{lstm_original_paper}, cette architecture de réseaux de neurones récurrents est doté d'un système de \textit{portes} qui filtrent l'information qui y passe ainsi que d'un état interne de la cellule mémoire d'un LSTM , ainsi nous pouvons décortiquer les composantes d'une cellule LSTM (voir \ref{lstm_architecture}) comme suit : 
		\begin{figure}[H]
			\centering
			\includegraphics[width=0.55\linewidth]{images/notions/lstm_arch.png}
			\caption{Architecture interne d'une cellule mémoire dans un réseau LSTM \cite{rnns_online}}
			\label{lstm_architecture}
		\end{figure}
		\begin{itemize}
			\item \textbf{Porte d'entrée (Input gate): } C'est une unité de calcul qui laisse passer certaines informations en entrée en utilisant une fonction d'activation sigmoïde pour pondéré les composantes du vecteur d'entrée à une étape $t$ et celles du vecteur d'état interne à l'étape $t-1$ (1: laisser passer, 0: ne pas laisser passer) et ainsi générer un vecteur candidat $C_t$ \cite{lstm_original_paper}.
			\begin{equation}
			\begin{gathered}
			i_t = \sigma(W_i \times [h_{t-1},x_t] + b_i) \\
			\tilde{C}_t = \tanh(W_C \times [h_{t-1},x_t] + b_C)
			\end{gathered}
			\end{equation}
			
			\item \textbf{Porte d'oubli (Forget gate): } De manière similaire, cette porte permet de spécifier au fur et à mesure de l'apprentissage les informations à oublier, qui sont donc peu importantes \cite{lstm_original_paper,rnn_lstms}.
			
			\begin{equation}
			\begin{gathered}
			f_t = \sigma(W_f \times [h_{t-1},x_t] + b_f)
			\end{gathered}
			\end{equation}
			
			\item \textbf{État interne de la cellule (Internal cell's state ): } C'est une sorte de convoyeur qui fait circuler l'information à travers la cellule, cet état est mis à jour à travers la combinaison des deux valeurs précédemment filtré par les portes $f_c$ et $i_c$\cite{lstm_original_paper}.
			
			\begin{equation}
			\begin{gathered}
			C_t = f_t * C_{t-1} + i_t*\tilde{C}_t
			\end{gathered}
			\end{equation}
			 
			\item \textbf{Porte de sortie (Output gate): } Pour renvoyer un résultat comme état interne du réseau, la cellule filtre son vecteur d'état et le combine avec la donné en entrée et l'état du réseau précédent pour ne laisser passer que certaines informations \cite{rnns_online,lstm_original_paper,rnn_lstms}.
			
			\begin{equation}
			\begin{gathered}
			o_t =  \sigma(W_o \times [h_{t-1},x_t] + b_o) \\
			h_t = o_t * \tanh(C_t)
			\end{gathered}
			\end{equation}
		\end{itemize}
	
	\subsubsection{Modèle basé N-grammes}
	\paragraph{}
	Très souvent quand il est nécessaire de traiter un ensemble de mots, phrases ou bien tout entité atomique qui constitue une séquence, il serait intéressant de pouvoir assigner une probabilité de vraisemblance à une séquence (de mots par exemple) en particulier. 
	\par Dans un contexte textuel, un N-gramme est une suite de N mots consécutifs qui forment une sous-chaîne $S\prime$ d'une chaîne de caractères $S$. Un exemple d'un ensemble de bi-grammes (2-grammes) pour la phrase "Ouvre le fichier \textit{home}" serait donc : (Ouvre,le), (le,fichier), (fichier,\textit{home}).
	\par 
	Ainsi, en disposant d'un corpus de texte assez large et diversifié et d'une méthode de comptage efficace, il serait possible de calculer la vraisemblance d'apparition d'un mot $w$ après une certaine séquence de mots $t$ sous forme d'une probabilité $P$ \cite{nlp_ngrams}.
	\begin{equation}
		P(w|t) = \frac{Comptage(t,w)}{Comptage(t)}
	\end{equation}
	\subsubsection{Modèle de Markov caché (Hidden Markov Models HMM)}
	\paragraph{}
	Informellement, un modèle de Markov caché (HMM) est un outil de de représentation pour modéliser la distribution de probabilité d'une séquence d'observations. Il est dit \textit{caché} pour deux raisons. Premièrement, il est assumé qu'une observation $O$ à un instant $t$ (dénotée $O_t$)  est le résultat d'un certain processus (souvent stochastique) dont l'état $S_t$ est caché à l'observateur. Deuxièmement, l'état $S_t$ du processus caché ne dépend uniquement que de sont état à l'instant $t-1$, il est alors dit que ce processus est Markovien ou qu'il satisfait la propriété de Markov \cite{hmm_intro,markov_process}.
	\par D'un façon plus formelle, un HMM est un 5-tuple $<(S,V,\Pi,A,B>$ \cite{hmm_formal} où :
	\begin{itemize}
		\item $S = \lbrace s_1 ... s_N \rbrace$ est l'ensemble fini des $N$ états du processus sous-jacent.
		\item $V = \lbrace v_1 ... v_M \rbrace$ est l'ensemble des $M$ symboles qui constituent un certain vocabulaire.
		\item $\Pi = \lbrace \pi_i \rbrace$ est une distribution initiale des probabilité d'états tel que $\pi_i$ est la probabilité de se trouver à l'état $i$ à l'instant $t=0$, bien évidement $\sum_{i=1}^{N} \pi_i = 1$ 
		\item $A=\lbrace a_{ij} \rbrace$ est une matrice $NxN$ dont chaque entrée $a_{ij}$ est la probabilité de transition d'un état $i$ à un état $j$ avec $\sum_{j=1}^{N} a_{ij} = 1$ pour tout $i,j = 1...N$.
		\item $B=\lbrace b_i(v_k)\rbrace$ est l'ensemble des distribution de probabilités d'émission (ou d'observation), donc $b_i(v_k)$ est la probabilité de générer un symbole $v_k$ du vocabulaire étant donné un certain état $i$ avec $\sum_{k=1}^{M} b_{i}(v_k) = 1$ pour tout $i= 1...N$. 
		
		\begin{figure}[H]
			\centering
			\includegraphics[width=0.65\linewidth]{images/notions/hmm.png}
			\caption{Exemple d'une distribution de probabilité de transition ainsi qu'une distribution de probabilité d'observations pour un HMM à 3 états et 2 observations }
			\label{hmm_process}
		\end{figure}
	\end{itemize}
	\par
	Le but serait de trouver la séquence d'états $S_{1:K}$ qui maximiserait la probabilité \cite{hmm_intro} : 
	\begin{equation}
		P(Y_{1:K} | O_{1:K}) = P(O_1)P(O_1|S_1)\prod_{t=2}^{K}P(S_t|S_{t-1})P(O_t|S_t) 
	\end{equation}
	\newpage
	Pour y parvenir d'une manière efficace, un décodeur qui implémente l'algorithme de viterbi peut être utiliser \cite{viterbi,viterbi_hmm}
\section{Schéma globale d'un SPA}
	\paragraph{}
	Durant nos lectures des différents travaux sur le domaine, nous pouvons dresser un schéma assez générale qui englobe les principaux modules d'un SPA : 
	\begin{figure}[H]
		\centering
		\includegraphics[width=0.75\linewidth]{images/SPA_diagram_2.png}
		\caption{Schéma abstractif d'un SPA \cite{spa_arch}}
		\label{spa_diagram}
	\end{figure}
	\paragraph{}
	Le processus peut être résumé en des étapes cruciales (qui seront détaillées dans les section suivante) : 
	\begin{itemize}
		\item L'utilisateur énonce une requête en utilisant sa voix, le signal est ensuite transformé en sa version textuelle.
		\item La requête étant sous un format textuel brut ne peut pas être interprété ou comprise par la machine, une représentation sémantique est générée qui compactera les principales informations contenues dans la requête, à savoir l'intentions de l'utilisateur et ses arguments.
		\item Au fur et à mesure que l'utilisateur énonce des requête, le système doit pouvoir être capable d'utiliser le contexte du dialogue pour interagir avec ce dernier pour pouvoir atteindre le but final du dialogue (exécuter uen commande système, trouver des informations sur le web ou sur la machine locale ...), le gestionnaire du dialogue communique avec son environnement en utilisant la même représentation sémantique produite par l'analyse précédente.
		\item Puisqu'il est préférable de cacher à l'utilisateur tout comportement interne au système, il sera préférable de transformer la trame sémantique (voir \ref{semantic_frame}) en texte naturelle pour l'afficher en sortie.
	\end{itemize}
	\paragraph{}
	Il est à noter que chacun des modules seront indépendant pour ce qu'il est de leur fonctionnement interne, ainsi aucun n'assumera un fonctionnement arbitraire, seul le format des informations qui circulent entre eux devra être établi au préalable pour un fonctionnement durable et robuste au changement.
	\paragraph{}
	Pour ce qui en est de la suite du chapitre, nous allons présenter les différents modules ainsi que les techniques et architectures qui sont considérés comme étant un état de l'art du domaine. 
\section{Reconnaissance automatique de la parole (ASR)}
	\paragraph{}
	Le premier module qui compose le système est celui de la reconnaissance automatique de la parole (ASR), le but d'un tel système (ou sous-système dans notre cas) est de convertir un signal audio décrivant la locution d'un utilisateur en un texte qui peut être interprété par la machine \cite{asr_definition}. Différentes approches ont été développé au court des années, une architecture s'est ensuite dégagée, les systèmes passent par deux phases : La phase d'apprentissage et la phase de reconnaissance. La première consiste a collecter les données qui constituent le corpus d'apprentissage, un ensemble de fichiers audios avec leurs transcriptions en texte et en phonèmes, le signal est ensuite traité pour en extraire des vecteurs de caractéristiques (ou attributs), la suite de l'apprentissage consiste à initialiser le HMM, lui passer les vecteurs précédemment extraits puis de l'enregistrer pour la phase suivante qui est la reconnaissance. Dans la deuxième phase le signal audio passe par le même procédé d'extraction des attributs, en utilisant un algorithme de décodage approprié \cite{viterbi_hmm}, la séquence d'observation passe par le HMM et la meilleure séquence de mots est sélectionnée \cite{speech_reco_Yu2015}.
	\par Une architecture assez générale s'est dégagée, quatre modules sont impliqué dans le processus de la reconnaissance, nous les citerons dans les sections qui suivent en citant les modèles utilisés dans chacun.
	
	\begin{figure}[H]
		\centering
		\label{ASR_schema}
		\includegraphics[width=0.75\linewidth]{images/ASR/schema.png}
		\caption{Architecture des systèmes de reconnaissance de la parole \cite{speech_reco_Yu2015}}
	\end{figure}
	
	\subsection{Acquisition du signale et extraction d'attributs}
		\paragraph{}
		l'étape consiste à extraire une séquence de vecteurs caractéristiques à partir du signal audio, fournissant une représentation compacte de ce dernier. Le processus démarre par la segmentation du signal en \textit{trames}, une transformation de fourrier est ensuite appliquée à ces dernières pour engendrer un spectre de magnitude qui sera ensuite passé à un module de transformation en spectre de Mel (Mel-Spectrum) qui est une sorte de changement d'échelle, finalement, une transformation inverse de fourrier est appliqué pour engendrer le Mel-Cpestrum qui est le vecteur d'attributs que nous recherchions \cite{asr_extraction}. Un tel processus peut utiliser plusieurs techniques pour la mise à l'échelle: MFCC (Mel-frequency cepstrum) \cite{MFCC}, LPC (Linear Predictive coding) \cite{LSP} et RASTA (RelAtive SpecTrAl) \cite{RASTA}, chacune possédant ses avantages et ses inconvénients.
	\subsection{Modélisation acoustique et du lexique}
		\paragraph{}
		C'est le cœur du système de reconnaissance, le but est de construire un modèle permettant d'identifier une séquence de phonèmes à partir d'une séquence d'observations de vecteurs d'attributs, ceci peut être fait on utilisant un modèle HMM et en disposant d'un corpus de fichiers audio accompagnés de leurs transcriptions en phonèmes et en texte \cite{hmm_acoustic_model,hmm_formal}, ou bien un réseau de neurones profonds \cite{speech_reco_Yu2015}, ou encore une hybridation de ces derniers \cite{dnn-hmm_acoustic_model}. Le modèle acoustique procède après la reconnaissance de la séquence de phonèmes au décodage de ce derniers, ceci est fait en utilisant un dictionnaire linguistique qui transcrit chaque mots du vocabulaire en les phonèmes qui le constituent, ceci peut induire à un cas d'ambiguïté où plusieurs mots peuvent avoir la même transcription phonétique (ou bien aucun mot ne correspond à cette séquence). Pour lever cette ambiguïté un modèle de langue est nécessaire pour décider quelle est la séquence de mots la plus probable qui coïncide avec la séquence de phonèmes observée.  
	\subsection{Modélisation de la langue}
		\paragraph{}
		Cette étape consiste à modéliser les aspects linguistiques de la langue que le système essaye de traiter, souvent spécifique au domaine d'application pour restreindre l'espace de recherche des mots reconnaissables par ce dernier et déterminer la séquence de mots en sortie la plus plausible. les modèles utilisés sont basé soit sur des grammaires à contexte libre dans le cas où les séquences de mots reconnaissables sont peut variées et peuvent être modélisées par le biais de règles de la langue \cite{LM_grammar}. Dans un cadre plus récent, les modèles probabilistes basé sur les N-grammes sont utilisés. Disposant d'un volume de données textuelles assez conséquent, l'utilisation de modèle basés sur les N-grammes ont prouvé leurs utilité \cite{nlp_ngrams,speech_reco_Yu2015,LM_n-grams}
		
		
\section{Compréhension du langage naturel (NLU)}
	\paragraph{}
	Après avoir obtenu la requête de l'utilisateur, le module qui prend le relai est celui de la compréhension du langage naturel. Ce domaine fait partie du traitement automatique du langage naturel (NLP), il est principalement focalisé sur les tâches qui traitent le niveau sémantique voir même pragmatique de la langue tel que la classification de texte, l'analyse de sentiments ou encore le traitement automatiques des e-mails. Dans le contexte d'un SPA, le but final d'un module de compréhension du langage naturel est de construire une représentation sémantique de la requête de l'utilisateur, étant donné une telle requête préalablement transformé en texte brut dans un langage naturel le module essayera d'en extraire une information primordiale qui est l'intention du locuteur. Une intention (ou intent) est une abstraction sémantique d'un but ou d'un sous-but de l'utilisateur, plusieurs requêtes de l'utilisateur peuvent avoir le même intent, ce qui rend l'utilisation d'une telle représentation essentielle pour que la machine puise mieux comprendre l'utilisateur.
	\subsection{Classification d'intentions}
		\paragraph{}
		La classification d'intentions à partir d'un texte est une tâche réalisable avec des techniques récentes d'apprentissage automatique, plus précisément en utilisant des modèles basé sur les réseaux de neurones récurrents à mémoire court et long terme (LSTM) (voir \ref{lstm_architecture}). Dans \cite{intent_classification} et \cite{intent_slots} deux architectures ont fait leurs preuves, dans le premier travail les auteurs ont utilisé une architecture BLSTM (LSTM Bidirectionnel) pour capturer les contextes droit et gauche d'un mot donné \cite{blstm}, le dernier état caché retourné par la cellule LSTM est ensuite utilisé pour la classification, une couche d'attention est ajoutée \cite{attention_mechanism} pour permettre au modèle de se focaliser sur certaines parties du texte en entrée. La deuxième architecture est un peu plus simpliste, en effet elle utilise des cellules LSTM basiques avec une couche de classification sur le dernier état, l'avantage est le temps d'apprentissage assez réduit au détriment d'une erreur de classification moins accrue mais toujours dans les normes.
		\begin{figure}[H]
			\centering
			\label{LSTM_intent}
			\includegraphics[width=0.65\linewidth]{images/NLU/intent_classification.png}
			\caption{Architecture de base d'un classificateur d'intents \cite{intent_classification}}
		\end{figure}
	\newpage
	\subsection{Extraction d'entités}
		\paragraph{}
		Déterminer l'intention d'un utilisateur ne s'arrête pas qu'au stade de l'identification de ce dit intent, en effet pour mieux représenter l'information récolté depuis la requête il faut en extraire des entités (nommés ou spécifiques au domaine) qui seront des arguments de l'intent identifié, cette tâche consiste donc à, pour un intent $I$ donné, extraire les arguments $Args$ qui lui sont appropriés depuis le texte de la requête. Plusieurs approches sont possibles, dans \cite{intent_slots} les auteurs ont taclé le problème comme étant la traduction d'une séquence de mots en entrée en une séquence d'entités en sortie, le schéma suivant explicite le processus :
		\begin{figure}[H]
			\centering
			\label{LSTM_slots}
			\includegraphics[width=0.80\linewidth]{images/NLU/seq2seq.png}
			\caption{Architecture de base d'un classificateur d'intents doublé d'un extracteur d'entité \cite{intent_slots}}
		\end{figure} 
	\subsection{Analyse sémantique}
		\paragraph{}
		Disposant des deux modèles précédemment cités, le module NLU peut maintenant construire une représentation sémantique adéquate qui va être transmise au module suivant qui sera le gestionnaire du dialogue, l'avantage d'voir en sortie une structure sémantique universelle est la non dépendance par rapport à la langue de l'utilisateur, en effet le système pourra encore fonctionner si une correspondance entre la nouvelle langue et le format choisi pour la représentation sémantique peut être trouvé. Le module donnera donc en sortie une trame sémantique (Semantic frame) qui comprendra les informations préalablement extraite, à savoir l'intent et les arguments (slots) qui lui sont propres \cite{intent_classification,intent_slots,semantic_frame} 
		\begin{figure}[H]
			\centering
			\label{semantic_frame}
			\includegraphics[width=0.80\linewidth]{images/NLU/semantic_frames.png}
			\caption{Example d'une trame sémantique pour une requête donnée}
		\end{figure} 
\section{Gestion du dialogue}
	\paragraph{}
	La compréhension du langage naturel permet de transformer un texte en une représentation sémantique. Afin qu’un système puisse réaliser un dialogue aussi anthropomorphe que possible, il doit décider, à partir des représentations sémantiques reçues au cours du dialogue, quelle action à prendre à chaque étape de la conversation. Celle-ci est transmise au générateur du langage naturel \ref{NLG} pour afficher un résultat à l’utilisateur. On distingue deux principaux modules généralement présents dans les systèmes de gestion de dialogue:
\begin{itemize}
	\item Un module qui met à jour l’état du gestionnaire de dialogue.
	\item Un module qui détermine la politique d’action du gestionnaire de dialogue.
\end{itemize}

\begin{figure}[H]
	\centering
	\includegraphics[width=.7\linewidth]{images/DM/DMGeneral.png} 
	\caption{Schéma général d'un gestionnaire de dialogue} 
\end{figure}


	\subsection{Processus de décision Markovien (MDP)}\label{MDP}
	\paragraph{}Un gestionnaire de dialogue peut être modélisé par un processus de décision Markovien\cite{Bel1957}. Ce dernier est modélisé par un 4-tuple ($S,A,P,R$)(*):
	\begin{itemize}
		\item $S$: ensemble des états du système.
		\item $A$: ensemble des actions du système.
		\item $P$: distribution de probabilités de transition entre états sachant l’action prise. $P(s’/s,a)$ est la probabilité de passer à l’état $s’$ sachant qu’on était à l’état $s$ après avoir pris l’action $a$.
		\item $R$: est la récompense reçue immédiatement après avoir changer l’état avec une action donnée. $R(s’/s,a)$ est la récompense reçu après avoir passer à l’état $s’$ sachant qu’on était à l’état $s$ après avoir pris l’action $a$.
	\end{itemize}
	D’après (*) un MDP, à tout instant $t$, est dans un état $s$. Dans notre cas c’est l’état du gestionnaire de dialogue. Il peut prendre une action $a$ afin de passer à un nouvel état $s’$. Sur ce fait, il reçoit une récompense qui ,dans notre cas, est une mesure sur les performances du système de dialogue. Le but est de maximiser les récompenses reçues.
	
	\begin{figure}[H]
		\centering
		\includegraphics[width=.95\linewidth]{images/DM/MDP.png} 
		\caption{Schéma représentant les transitions entre états dans un MDP} 
	\end{figure}
	
	
	\subsection{État du gestionnaire de dialogue}
		\paragraph{}
		L’état d’un système de dialogue est une représentation sémantique qui contient des informations sur le but final de l’utilisateur ainsi que l’historique de la conversation. La représentation souvent utilisée dans les systèmes de dialogue est celle du cadre sémantique \cite{Chen2017}. Cette structure contient des emplacements à remplir sur un domaine donné, la figure \ref{SFrame} illustre un exemple de cadre sémantique.\newline
		
		\begin{figure}[H]
			\centering
			\includegraphics[width=.7\linewidth]{images/DM/SFrame.png} 
			\caption{Schéma représentant un cadre sémantique avec comme domaine: création de fichier} 
			\label{SFrame}
		\end{figure}


À l’arriver d’une nouvelle information, un module dédié met à jour l’état du gestionnaire de dialogue. Comme l’action du système de dialogue est décidée à partir de son état, cette tâche est donc essentiel au bon fonctionnement du système. Plusieurs méthodes ont été proposées pour gérer le suivi de l’état du gestionnaire de dialogue.
\subsubsection{Suivi de l’état avec une base de règles}
\paragraph{}
La méthode traditionnelle utilisée consiste à écrire manuellement les règles à suivre lors de l’arrivé d’une nouvelle information pour mettre à jour l’état\cite{Goddeau1996}. Cependant, les bases de règles sont très susceptibles à faire des erreurs\cite{Chen2017} comme ils sont peu robuste face aux incertitudes.


\begin{figure}[H]
	\centering
	\includegraphics[width=.7\linewidth]{images/DM/RuleBasedUpdate.png} 
	\caption{Schéma représentant la mise-à-jour de l'état par un système basé règles} 
\end{figure}

\subsubsection{Suivi de l’état avec des méthodes statistiques}
Le suivi dans ce cas se fait en gardant une distribution de probabilités sur l’état du système. D’où, l’utilisation des processus de décision markovien partiellement observable (POMDP)\cite{Young2010} qu’on introduira par la suite. Dans ce cas, le système garde une distribution de probabilités sur les valeurs possibles des différents emplacements du cadre sémantique.

\begin{figure}[H]
	\centering
	\includegraphics[width=.7\linewidth]{images/DM/StatBasedUpdate.png} 
	\caption{Schéma représentant la mise-à-jour de l'état par un système basé statistiques} 
\end{figure}

\subsubsection{Processus de décision markovien partiellement observable (POMDP)}
\paragraph{}
Comme dans les processus de décision markovien, un POMDP\cite{Astrom1965} passe d’un état à un autre en prenant une des actions possibles. Cependant, ce dernier ne connait pas l’état exacte dans lequel il se trouve à un instant $t$. Il reçoit par contre une observation, dans notre cas c’est l’action de l’utilisateur, à partir de laquelle il peut estimer une distribution de probabilités sur l’état actuel. Pour résumer cela, un POMDP est un 6-tuple ($S,A,P,R,M,O$):
\begin{itemize}
\item Les 4 premiers composants sont les mêmes que ceux d’un MDP \ref{MDP}.
\item $M$: l’ensemble des observations.
\item $O$: distribution de probabilités sur les observations $o$ en connaissant l’état et l’action prise pour y arriver. $O(o|s,a)$ est la probabilité d’observer $o$ sachant qu’on se trouve à l’état $s$ et qu’on a pris l’action $a$ pour y arriver.
\end{itemize}

\begin{figure}[H]
	\centering
	\includegraphics[width=.5\linewidth]{images/DM/POMDP.png} 
	\caption{Diagramme d'influence dans un POMDP} 
\end{figure}

\subsubsection{Suivi de l’état avec réseaux de neurones profonds}
\paragraph{}
Récemment, des approches utilisant les réseaux de neurones profonds\ref{part2DNN} ont fait leurs apparitions. En effet, l'utilisation des architectures profondes permet de capter des relations complexes entre les caractéristiques d'un dialogue et ainsi mieux estimer l'état du système. Le réseau de neurones estime les probabilités de toutes les valeurs possibles d’un emplacement du cadre sémantique\cite{Henderson2013}. En conséquence, il peut être utilisé comme modèle de suivi d'état pour un processus partiellement observable.

	\subsection{Politique de gestion de dialogue}
		\paragraph{}
		La première partie était dédiée au module qui suit l’état du système de dialogue. Dans cette partie, Nous allons présenter des approches proposées afin d’arriver au but du MDP, c’est à dire quelles actions prendre pour maximiser la somme des récompenses obtenues.
		\subsubsection{Gestion de dialogue avec une base de règles}
		\paragraph{}
		Les premières approches utilisaient des systèmes de règles destiné à un domaine bien spécifique. Elles étaient déployées dans plusieurs domaines d’application pour leur simplicité. Cependant, le travail manuel nécessaire reste difficile à faire et, généralement, n’aboutit pas à des résultats flexibles qui peuvent suivre le flux du dialogue convenablement\cite{Lee2010}.
	\subsubsection{Gestion de dialogue par apprentissage}
		\paragraph{}
		La résolution d’un MDP revient à trouver une estimation de la fonction de récompense afin de pouvoir choisir la meilleure action. La majorité des approches récentes utilise l’apprentissage par renforcement pour but d’estimer la récompense obtenue par une action et un état donnés. Cette préférence par rapport aux approches supervisées revient à la difficulté de produire des corpus de dialogues\cite{Henderson2008}, encore moins des corpus annotés avec les récompenses à chaque transition. Néanmoins, il existe des approches de bout en bout qui exploitent des architectures avec réseaux de neurones profonds et traitent le problème comme Seq2Seq\ref{seq2seqpart2} afin de produire directement une sortie à partir des informations reçues de l’utilisateur\cite{Wen2017,Serban2016}.


\begin{figure}[H]
	\centering
	\includegraphics[width=.7\linewidth]{images/DM/DMSeq2Seq.png} 
	\caption{Schéma de gestion de dialogue de bout en bout avec architecture Seq2Seq} 
\end{figure}
\subsubsection{Apprentissage par renforcement} \label{reinf_learning}
\paragraph{}
L’apprentissage par renforcement est une approche qui a pour but d’estimer une politique d’actions à prendre dans un environnement. Celle-ci doit maximiser une mesure d’évaluation qui est sous forme de récompenses obtenues après chaque action\cite{Weisz2018}. L’environnement est souvent modélisé comme un MDP, ou éventuellement POMDP. L’agent d’apprentissage passe donc d’un état à un autre en prenant des actions dans cet environnement. L’apprentissage se fait dans ce cas en apprenant par l’expérience de l’agent, à savoir les récompenses obtenues par les actions prises et de quels états elles étaient prises. Il peut ainsi estimer la fonction de récompense pour pouvoir faire le choix d’actions optimales. 

\begin{figure}[H]
	\centering
	\includegraphics[width=.5\linewidth]{images/DM/RLSchema.png} 
	\caption{Schéma d'interaction agent-environnement dans l'apprentissage par renforcement} 
\end{figure}
Il existe plusieurs méthodes que l’agent peut utiliser pour estimer la fonction de récompense \cite{Dimitri2012}, notamment Deep Q Learning (DQN) \cite{Mnih2015} qui utilise les réseaux de neurones profonds pour trouver une approximation à cette fonction. Dans cette approche, à chaque fois que l'agent prend une action, il compare la récompense reçue avec celle estimée par le réseau de neurones, il applique ensuite l'algorithme de rétro-propagation pour corriger les erreurs du réseau. 

\paragraph{}
Le système de dialogue est modélisé par un MDP. Seulement, ce dernier inclut l’utilisateur comme partie de l’environnement. En conséquence, pour appliquer l’apprentissage par renforcement, il est nécessaire qu’un utilisateur communique avec le système pour qu’il apprenne. D’où, la nécessité d’utiliser les simulateurs d’utilisateur.

\paragraph{Simulateur d'utilisateur}
Un simulateur d’utilisateur est un programme qui se comporte comme un humain interagissant avec un système de dialogue. Celui-là doit pouvoir estimer sa satisfaction après une interaction. en d’autres termes, il doit comporter d'une fonction de récompense. Il existe plusieurs méthodes pour créer un simulateur d’utilisateur:
\begin{itemize}
	\item Les simulateurs d’utilisateur basé règles: dans ce cas une liste de règles est écrite manuellement que le simulateur doit suivre pour communiquer avec le système\cite{Schatzmann2007}.
	\item Les simulateurs d’utilisateur basé n-grammes: ils traitent un dialogue comme une séquence d’actions. Ils prennent les n-1 actions pour estimer l’action la plus probable que peut prendre le simulateur à partir des statistiques tirées d'un	 corpus de dialogues\cite{Georgila2005}.
	\item Les simulateurs d’utilisateur basé HMM: les états du modèle sont les états du système, les observations sont ses actions. Ainsi un HMM peut estimer l’état le plus probable du système pour prendre une action. Il existe d’autres variantes, IHMM et IOHMM, qui incluent les probabilités conditionnelles des actions de l'utilisateur sachant l’état du système ou l’action du système directement dans le modèle HMM\cite{Cuayhuitl2005}.
	\item Les simulateurs d’utilisateur avec apprentissage par renforcement: Comme le gestionnaire de dialogue, le simulateur apprend par renforcement au même temps. Dans ce cas la fonction de récompense pour les deux agents peut être apprise à partir des dialogues humain-humain\cite{Chandramohan2011}.
\end{itemize}







\section{Génération du langage naturel (NLG)}\label{NLG}
	\paragraph{}
	Le domaine de la génération automatique du langage naturel est l’un des domaines dont les bordures sont difficiles à définir\cite{evans2002}. il est vrai que la sortie d’un tel système est clairement du texte. Cependant, l’ambiguïté se trouve dans ses entrées, c’est à dire, sur quoi se basera le système pour générer le texte. D’après (Reiter \& Dale, 1997)\cite{Reiter:1997} la génération du langage naturel est décrite comme étant le sous domaine de l’intelligence artificielle qui traite la construction des systèmes de génération de texte à partir d’une représentation non-linguistique de l’information. Celle-ci peut être une représentation sémantique, des données numériques, une base de connaissances ou même des données visuelles (images ou vidéos). Ceci dit, d’autres travaux ,comme Labbé \& Portet (2012)\cite{Labbé2012}, utilisent les mêmes techniques pour des entrées linguistiques. Enfin la génération du langage naturel peut être très proche de la gestion de dialogue\cite{Dethlefs2014}, en effet, le texte généré doit prendre en compte l’historique de la conversation et le contexte de l’utilisateur.\newline
	Il existe six tâches trouvées fréquemment dans les systèmes de génération de texte \cite{Reiter:1997}.
	
	\subsection{Détermination du contenu}
	\paragraph{}
	Cette partie consiste à sélectionner les informations de l’entrée dont le système veut transmettre leur contenu sous forme de texte naturel à l’utilisateur. En effet, les données en entrée peuvent contenir plus d’informations que ce que l’on désire communiquer\cite{Yu:2007}. De plus, le choix de l'information peut aussi dépendre de l’utilisateur et de ses connaissances\cite{Dethlefs2014}. Ce qui requiert de mettre au point un système qui détecte les informations pertinentes à l’utilisateur.
	\subsection{Structuration de texte}
	\paragraph{}
	Après la détermination du contenu, le système doit ordonner les information à transmettre. Ceci dépend grandement du domaine d’application qui peut exiger des contraintes d’ordre temporelle ou de préférence par importance des idées. Les informations à transmettre en elles-mêmes sont souvent reliées par sens ce qui implique une certaine structuration de texte à respecter.\newpage
	\subsection{Agrégation de phrases}
	\paragraph{}
	Certaines informations peuvent être transmises dans une même phrase. Cette partie introduit des notions de la linguistique afin que le texte généré soit plus lisible et éviter les répétitions. Un exemple de cela peut être la description de la météo à Alger au cours de la matinée:
	\begin{itemize}
		\item Il va faire 16° à Alger à 7h.
		\item Il va faire 17° à Alger à 8h.
		\item Il va faire 18° à Alger à 9h.
		\item Il va faire 18° à Alger à 10h.
	\end{itemize}
	Ceci peut être agrégé en un texte plus compacte: "La température moyenne à Alger sera de 17° entre 7h et 10h."
	
	\subsection{Lexicalisation}
	\paragraph{}Le système choisit les mots et les expressions à utiliser pour communiquer le contenu des phrases sélectionnées. La difficulté de cette tâche revient à l’existence de plusieurs manières d’exprimer la même idée. Cependant, certains mots ou expressions sont plus appropriés en certaines situations que d’autres. En effet, “inscrire un but” est une façon inadéquate d’exprimer un but contre son camp\cite{Gatt2018}.
	
	\subsection{Génération d’expressions référentielles (REG)}
	\paragraph{}Cette partie du système se focalise dans la génération d’expressions référentielles qui peuvent être entre autres: noms propres, groupes nominaux ou pronoms et ceci a pour but d’identifier les entités du domaine. Cette tâche semble être très proche de sa prédécesseur; elle s’avère néanmoins plus délicate dû à la difficulté de confier suffisamment d’information sur l’entité afin de la différencier des autres\cite{Reiter:1997}. Le système doit faire un choix de l’expression référentielle en se basant sur plusieurs facteurs, par exemple “Mohammed”, “Le professeur” ou “Il” font référence à la même personne. Cependant, le choix entre eux dépendrait de si l’entité a été mentionnée auparavant et des détails l’accompagnant par exemple. 
	
	\subsection{Réalisation linguistique}
	\paragraph{}
	La dernière tâche consiste à combiner les mots et expressions sélectionnés pour construire une phrase linguistiquement correcte. Ceci requiert l’utilisation des bonnes formes morphologiques des mots, les ordonner et éventuellement  l’addition de certains mots du langage afin de réaliser une structure de phrase grammaticalement et sémantiquement correcte. Plusieurs méthodes ont été proposées, principalement les méthodes basées sur des règles manuellement construites (modèles de phrases, systèmes basés grammaires) ou des approches statistiques \cite{Gatt2018}.
	\paragraph{Modèles de phrases:} La réalisation se fait en utilisant des modèles de phrases prédéfinis. Il suffit de remplacer des espaces réservés par certaines entrées du système. Par exemple, une application dans un contexte météorologique pourrait utiliser le modèle suivant: “la température à [ville] atteint [température]° le [date]”.\\
Cette méthode est utilisée lorsque les variations des sorties de l’application sont minimales. Son utilisation a l’avantage et l’inconvénient d’être rigide. D’un coté il est facile de contrôler la qualité des sorties syntaxiquement et sémantiquement tout en utilisant des règles de remplissage complexe \cite{Theune2001}. Cependant, lorsque le domaine d’application présente beaucoup d’incertitude, cette méthode exige un travail manuel énorme, voire impossible à faire, pour réaliser une tâche pareille. Bien que certains travaux ont essayer de faire un apprentissage de modèles de phrases à partir d’un corpus\cite{Angeli2012} cette méthode reste inefficace lorsqu’il s’agit d’application qui nécessite un grand nombre de variations linguistiques.
	\paragraph{Systèmes basés grammaire:} La réalisation peut se faire en suivant une grammaire du langage. Celle-si contient les règles morphologiques et de structures de la langues, notamment la grammaire systémique fonctionnelle (SFG)\cite{Halliday2004} a été largement utilisé comme dans NIGEL\cite{Mann1983} ou KPML\cite{Bateman1997}. L’exploitation des grammaires dans la génération du texte nécessite généralement des entrées détaillées. En plus des composantes du lexique sélectionnées, des descriptions de leurs rôles ainsi que leurs fonctions grammaticales sont souvent exigées. Un exemple d’entrée d’un système basé grammaire est celui de SURGE\cite{Elhadad1996}:
	\begin{center}
		\begin{forest} [
			[cat:clause]
			[process
			[type[composite]]
			[relation[possessive]]
			[lex[\color{red}"hand"]]
			]
			[partic
			[agent
			[cat[pers\_pro]]
			[gender[feminine]]
			]
			[affected
			[(1)
			[cat[NP]]
			[lex[\color{red}"editor"]]
			]
			]
			[possessor[(1)]]
			[possessed
			[cat[NP]]
			[lex[\color{red}"draft"]]
			]
			]
			]
		\end{forest}
	\end{center}
	Qui génère la phrase: “She hands the draft to the editor”.\newline

Comme les modèles de phrases, les systèmes basés grammaire nécessite un énorme travail manuel. En particulier, il est difficile de prendre en compte le contexte en définissant les règles de choix entre les variantes possibles du texte résultat à partir des entrées\cite{Gatt2018}.

\paragraph{Approches statistiques:} Il existe plusieurs méthodes basées sur des statistiques pour la tâche de réalisation. Certains se basent sur des grammaires probabilistes, cette dernière a l’avantage de minimiser le travail manuel tout en couvrant plus de cas de réalisation. Il existe principalement deux approches l’utilisant\cite{Gatt2018}:
\begin{itemize}
	\item La première se base sur une petite grammaire qui génère plusieurs alternatives qui sont ensuite ordonnés selon un modèle statistique basé sur un corpus pour sélectionner la phrase la plus probable (par exemple Langkilde-Geary (2000)\cite{LangkildeGeary2000}).
	\item La deuxième méthode utilise les informations statistiques directement au niveau de la génération pour produire la solution optimale (exemple: Belz (2008)\cite{Belz2008}).
\end{itemize}
	Dans les deux méthodes sus-citées la grammaire de base peut être manuellement faite, dans ce cas, les informations statistiques aideront à la détermination de la solution optimale, ou elle peut être extraite à partir des données, comme l’utilisation des Treebanks \footnote{un Treebank est un texte analysé qui contient des informations syntaxiques ou sémantiques sur les structures de phrases} pour déduire les règles de grammaire\cite{Espinosa2008}.\newline
\paragraph{}
D’autres approches statistiques n’utilisent pas des grammaires mais se basent sur des classificateurs. Ces derniers peuvent être cascadés de telle sorte à décider quel constituant utiliser dans quelle position ainsi que les modifications nécessaires pour générer un texte correcte. À noter qu’une telle approche, ne nécessitant pas l’utilisation de grammaire, utilise des entrées plus abstraites et moins détaillées linguistiquement. À voire même la possibilité de s’étendre aux autres tâches de NLG, c’est à dire un système qui accomplit plusieurs tâches de NLG en parallèle en utilisant les entrées initiales. Dans la suite de ce travail nous allons présenter certains de ces systèmes qui sont plus utilisés récemment.

\subsection{Systèmes basés encodeur-décodeur}
\paragraph{}
Une architecture souvent utilisée dans le traitement du langage naturel est l’encodeur-décodeur (part2). En particulier, son utilisation dans les tâches seq2seq (part2) ce qui permet de mettre en correspondance une séquence de taille variable en entrée avec une autre séquence en sortie. Les modèles seq2seq peuvent être adapter pour convertir une représentation abstraite de l’information en langage naturel\cite{Ferreira2017}.\newline
\begin{figure}[H]
	\centering
	\includegraphics[width=.95\linewidth]{images/NLG/Encoder.png} 
	\caption{Schéma d'une architecture encodeur-décodeur pour NLG} 
\end{figure}
\paragraph{}
Beaucoup d’approches de génération de langage naturel en gestion de dialogue utilise des encodeur-décodeur. Wen et al. (2015)\cite{Wen2015} utilise par exemple des LSTMs(part2) sémantiquement conditionnés; il ajoute aux LSTMs classiques une couche contenant des informations sur l’action prise par le gestionnaire de dialogue pour assurer que la génération représente le sens désiré. D’autres travaux utilisent des réseaux de neurones récurrent (part2) pour encoder l’état du gestionnaire de dialogue et l’entrée reçu suivis par un décodeur pour générer le texte de la réponse\cite{Sordoni2015,Serban2016,Goyal2016}.
	